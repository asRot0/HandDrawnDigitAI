{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1nkFSEzYpDmA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "outputId": "e45a0009-1180-4f1b-9db1-b71c666540db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 128ms/step - accuracy: 0.9021 - loss: 0.3285 - val_accuracy: 0.9785 - val_loss: 0.0814\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 129ms/step - accuracy: 0.9728 - loss: 0.1005 - val_accuracy: 0.9838 - val_loss: 0.0528\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 127ms/step - accuracy: 0.9807 - loss: 0.0761 - val_accuracy: 0.9831 - val_loss: 0.0609\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m240s\u001b[0m 128ms/step - accuracy: 0.9844 - loss: 0.0641 - val_accuracy: 0.9856 - val_loss: 0.0487\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 127ms/step - accuracy: 0.9844 - loss: 0.0585 - val_accuracy: 0.9851 - val_loss: 0.0550\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 128ms/step - accuracy: 0.9877 - loss: 0.0471 - val_accuracy: 0.9889 - val_loss: 0.0379\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m261s\u001b[0m 127ms/step - accuracy: 0.9891 - loss: 0.0405 - val_accuracy: 0.9893 - val_loss: 0.0376\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 129ms/step - accuracy: 0.9891 - loss: 0.0433 - val_accuracy: 0.9882 - val_loss: 0.0410\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m259s\u001b[0m 128ms/step - accuracy: 0.9902 - loss: 0.0377 - val_accuracy: 0.9856 - val_loss: 0.0620\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 127ms/step - accuracy: 0.9900 - loss: 0.0388 - val_accuracy: 0.9738 - val_loss: 0.0957\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step - accuracy: 0.9671 - loss: 0.1169\n",
            "Test Accuracy: 0.973800003528595\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nFlyNet Model Architecture:\\n\\n1. **Initial Conv Layer**:\\n   - Conv2D layer with 32 filters, kernel size 7x7, stride 2, and padding \"same\".\\n   - Batch Normalization and ReLU activation.\\n   - MaxPooling with pool size 2x2, stride 2.\\n\\n2. **FlyNet Blocks**:\\n   - Each block contains two Conv2D layers with Batch Normalization after each layer.\\n   - The first Conv2D uses \"relu\" activation, and the second uses \"tanh\" activation.\\n\\n   - Block 1: 32 filters.\\n   - Block 2: 64 filters, followed by MaxPooling with pool size 2x2, stride 2.\\n   - Block 3: 128 filters.\\n   - Block 4: 256 filters.\\n\\n3. **Global Average Pooling and Dense Layers**:\\n   - Global Average Pooling layer reduces spatial dimensions to 1x1.\\n   - Flatten layer.\\n   - Dense layer with 128 units and ReLU activation, followed by a Dropout layer with 50% rate.\\n   - Dense layer with 10 units and softmax activation for classification.\\n\\nModel Summary:\\nThe summary provides detailed information on each layer, its output shape, and the number of parameters.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Define DefaultConv2D with partial\n",
        "DefaultConv2D = keras.layers.Conv2D\n",
        "\n",
        "# Define FlyNet layer\n",
        "class FlyNetBlock(keras.layers.Layer):\n",
        "    def __init__(self, filters, activation1=\"relu\", activation2=\"tanh\", **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv1 = DefaultConv2D(filters, kernel_size=3, padding=\"same\", activation=activation1)\n",
        "        self.bn1 = keras.layers.BatchNormalization()\n",
        "        self.conv2 = DefaultConv2D(filters, kernel_size=3, padding=\"same\", activation=activation2)\n",
        "        self.bn2 = keras.layers.BatchNormalization()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        return x\n",
        "\n",
        "# Build FlyNet model\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "# Initial Conv layer\n",
        "model.add(DefaultConv2D(32, kernel_size=7, strides=2, padding=\"same\", input_shape=[28, 28, 1], activation=\"relu\"))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
        "\n",
        "# Add FlyNet Blocks\n",
        "model.add(FlyNetBlock(32))\n",
        "model.add(FlyNetBlock(64))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=2, strides=2))\n",
        "model.add(FlyNetBlock(128))\n",
        "model.add(FlyNetBlock(256))\n",
        "model.add(keras.layers.GlobalAveragePooling2D())\n",
        "\n",
        "# Final Dense layers\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Load and preprocess MNIST data\n",
        "mnist = keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train[..., tf.newaxis] / 255.0\n",
        "x_test = x_test[..., tf.newaxis] / 255.0\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), batch_size=32)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc}\")\n",
        "\n",
        "# Model Architecture Description\n",
        "'''\n",
        "FlyNet Model Architecture:\n",
        "\n",
        "1. **Initial Conv Layer**:\n",
        "   - Conv2D layer with 32 filters, kernel size 7x7, stride 2, and padding \"same\".\n",
        "   - Batch Normalization and ReLU activation.\n",
        "   - MaxPooling with pool size 2x2, stride 2.\n",
        "\n",
        "2. **FlyNet Blocks**:\n",
        "   - Each block contains two Conv2D layers with Batch Normalization after each layer.\n",
        "   - The first Conv2D uses \"relu\" activation, and the second uses \"tanh\" activation.\n",
        "\n",
        "   - Block 1: 32 filters.\n",
        "   - Block 2: 64 filters, followed by MaxPooling with pool size 2x2, stride 2.\n",
        "   - Block 3: 128 filters.\n",
        "   - Block 4: 256 filters.\n",
        "\n",
        "3. **Global Average Pooling and Dense Layers**:\n",
        "   - Global Average Pooling layer reduces spatial dimensions to 1x1.\n",
        "   - Flatten layer.\n",
        "   - Dense layer with 128 units and ReLU activation, followed by a Dropout layer with 50% rate.\n",
        "   - Dense layer with 10 units and softmax activation for classification.\n",
        "\n",
        "Model Summary:\n",
        "The summary provides detailed information on each layer, its output shape, and the number of parameters.\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eR5N0rB5gx8d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}